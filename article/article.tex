% !TEX root = ./article.tex

\documentclass{article}

\usepackage{mystyle}
\usepackage{myvars}



%-----------------------------

\begin{document}

	\maketitle % Insert title

	\thispagestyle{fancy} % All pages have headers and footers


%-----------------------------
%	ABSTRACT
%-----------------------------

	\begin{abstract}
		\noindent [TODO ]
	\end{abstract}

%-----------------------------
%	TEXT
%-----------------------------


	\section{Introducción}
	\label{sec:introducción}

		\paragraph{}
		[TODO]

	\section{La figura \ref{e1:plot} muestra un conjunto de entrenamiento con ejemplos positivos (estrellas) y negativos (círculos). Se desea clasificar la nueva instancia $<3,3>$ mediante el algoritmo $K$-vecinos más próximos. Obtener la clasificación para los valores de $K=\{ 1, 3, 5\}$ utilizando las distancias indicadas a continuación}
	\label{sec:e1}

		\paragraph{}
		[TODO]

		\begin{figure}[h]
			\begin{center}
				\includegraphics[width=0.5\textwidth]{exercise-1-plot}
			\end{center}
			\caption{Representación Gráfica del problema \ref{sec:e1}}
			\label{e1:plot}
		\end{figure}

		\begin{align}
		\label{eq:estrellas}
			ESTRELLAS &= \{(1,1), (1,4), (3,1), (5,3)\}
		\end{align}

		\begin{align}
		\label{eq:circulos}
			CIRCULOS &= \{(2,1), (5,2), (6,1)\}
		\end{align}

		\begin{align}
		\label{eq:instancia}
			instancia &= (3,3)
		\end{align}


		\begin{align}
			max_x = 6 && min_x = 1 \\
			max_y = 4 && min_y = 1
		\end{align}

		\begin{align}
		\label{eq:normalization}
			normalize(x,y) &= (\frac{x-min_x}{max_x-min_x},\frac{y-min_y}{max_y-min_y})
		\end{align}


		\begin{align}
		\label{eq:estrellas_normalized}
			ESTRELLAS_{normalized} &= \{(0,0), (0,1), (\tfrac{2}{5},0), (\tfrac{4}{5},\tfrac{2}{3})\}
		\end{align}

		\begin{align}
		\label{eq:circulos_normalized}
			CIRCULOS_{normalized}  &= \{(\tfrac{1}{5},0), (\tfrac{4}{5},\tfrac{1}{3}), (1,0)\}
		\end{align}

		\begin{align}
		\label{eq:instancia_normalized}
			instancia_{normalized}  &= (\tfrac{2}{5},\tfrac{2}{3})
		\end{align}

		\subsection{Distancia Euclídea}


			\begin{align}
				D_{euclidean}(a,b) &= \sqrt{(a_x - b_x)^2 + (a_y - b_y)^2}
			\end{align}

			\begin{align}
				R_{euclidean} &= \{0.777_e, 0.52_e, 0.666_e, 0.4_e, 0.696_c, 0.52_c, 0.896_c\}
			\end{align}

			\paragraph{}
			[TODO]

			\begin{align}
				min(R_{euclidean},1) &= \{ 0.4_e \} \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{euclidean},3) &= \{ 0.4_e, 0.52_e, 0.52_c\} \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{euclidean},5) &= \{ 0.4_e, 0.52_e, 0.52_c, 0.666_e,  0.696_e \} \implies instancia \in ESTRELLAS
			\end{align}

		\subsection{Distancia Euclídea Ponderada: $w_x=0.2, w_y=0.8$}

			\paragraph{}
			[TODO]

			\begin{align}
				D_{w_{euclidean}}(a,b) &= \sqrt{w_x(a_x - b_x)^2 + w_y(a_y - b_y)^2} = \sqrt{0.2(a_x - b_x)^2 + 0.8(a_y - b_y)^2}
			\end{align}

			\begin{align}
				R_{w_{euclidean}} &= \{0.622_e, 0.347_e, 0.596_e, 0.178_e, 0.602_c, 0.347_c, 0.653_c\}
			\end{align}

			\begin{align}
				min(R_{w_{euclidean}},1) &= \{ 0.178_e \}  \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{w_{euclidean}},3) &= \{ 0.178_e, 0.347_e, 0.347_c,\}  \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{w_{euclidean}},5) &= \{ 0.178_e, 0.347_e, 0.347_c, 0.596_e, 0.602_c\} \implies instancia \in ESTRELLAS
			\end{align}


		\subsection{Distancia de Manhattan}

			\paragraph{}
			[TODO]

			\begin{align}
				D_{manhattan}(a,b) &= |a_x - b_x| + |a_y - b_y|
			\end{align}

			\begin{align}
				R_{manhattan} &= \{4_e, 3_e, 2_e, 2_e, 3_c, 3_c, 5_c\}
			\end{align}

			\begin{align}
				min(R_{manhattan},1) &= \{ 2_e \}  \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{manhattan},3) &= \{ 2_e, 2_e, 3_e\}  \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{manhattan},5) &= \{ 2_e, 2_e, 3_e, 3_c, 3_c, \} \implies instancia \in ESTRELLAS
			\end{align}

		\subsection{Distancia de Hamming}

			\paragraph{}
			[TODO]

			\begin{align}
				D_{hamming}(a,b) &= (a_x \neq b_x) + (a_y \neq b_y)
			\end{align}

			\begin{align}
				R_{hamming} &= \{2_e, 2_e, 1_e, 1_e, 2_c, 2_c, 2_c\}
			\end{align}

			\begin{align}
				min(R_{manhattan},1) &= \{ 1_e \}  \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{manhattan},3) &= \{ 1_e, 1_e, 2_e\}  \implies instancia \in ESTRELLAS
			\end{align}

			\begin{align}
				min(R_{manhattan},5) &= \{ 1_e, 1_e, 2_e, 3_c, 3_c, \}  \implies instancia \in ESTRELLAS
			\end{align}

	\section{Dígitos manuscritos}

		\paragraph{}
		[TODO]

		\begin{table}[h]
			\centering
			\small
			\begin{tabu}{ | c | c | c | c | c | c | c | c | c | c | }
				\hline
				\multicolumn{10}{ | c | }{Validación cruzada de 10 particiones --- $K$-Vecinos más Próximos} \\ \hline
				\multirow{2}{*}{Datos}	& \multicolumn{9}{ c |}{Tasa de Error ($K=$)} \\ \cline{2-10}
																& \emph{1} & \emph{2} & \emph{3} & \emph{4} & \emph{5} & \emph{6} & \emph{7} & \emph{8}	& \emph{9}\\ \hline
				Entrenae						& $3.448\%$	 & $3.524\%$ & $3.065\%$ & $3.141\%$	& $3.371\%$ & $3.218\%$	 & $3.295\%$ & $3.295\%$ & $3.371\%$	\\
				\hline
			\end{tabu}
			\caption{Tasa de error obtenida tras realizar un experimento de Validación cruzada de 10 particiones con el clasificador \emph{K-NN} para $k \in \{1,2,...,9\}$}
			\label{table:e2}
		\end{table}



		\begin{figure}[h]
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						% only scale the axis, not the axis including the ticks and labels
		        scale only axis=true,
		        % set `width' and `height' to the desired values
		        width=0.9\textwidth,
		        height=0.3\textwidth,
						]
						\addplot table [x=k, y=error, col sep=comma] {data.csv};
					\end{axis}
				\end{tikzpicture}
			\end{center}
			\caption{Representación Gráfica de la tasa de error obtenida tras realizar un experimento de Validación cruzada de 10 particiones con el clasificador \emph{K-NN} para $k \in \{1,2,...,9\}$}
			\label{plot:e2}
		\end{figure}

		\paragraph{}
		[TODO]


%-----------------------------
%	Bibliographic references
%-----------------------------
	\nocite{garciparedes:machine-learning-instance-based}
	\nocite{subject:taa}
	\nocite{tool:weka}
  \bibliographystyle{alpha}
  \bibliography{bib/misc}

\end{document}
